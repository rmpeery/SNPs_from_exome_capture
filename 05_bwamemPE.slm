#!/bin/bash
#SBATCH --mail-user=you@emal.ca
#SBATCH --account=account
#SBATCH -t 0-6:00
#SBATCH --cpus-per-task=16
#SBATCH --mem-per-cpu=2G
#SBATCH --mail-type=ALL
#SBATCH --job-name=name
#SBATCH --array=1-864%50
# if you have a lot of files then throttle the array to be nice by using %25 or whatever

# so the whole script crashes if there is an error an not 500 ind. crashes
set -euo pipefail

# make sure these are the latest ones using module spider
module load StdEnv/2023 bwa-mem2/2.2.1
module load samtools/1.20

# change paths to match your structure
DIR="/home/path"
REF="$DIR/refs/ref.fasta"
TRIM_READS="$DIR/reads/trim"
OUT="$DIR/bam/sort"
METRICS="$DIR/metrics/mapping"

mkdir -p "$OUT" "$METRICS"

# grab fwd reads; check file extensions
mapfile -t FWD_READS < <(find "$TRIM_READS" -name "*_1P.fastq.gz" | sort)

# use read file to assign array job number
INDEX=$((SLURM_ARRAY_TASK_ID - 1)) # to start at 1 and not base 0
FWD="${FWD_READS[$INDEX]}"

# sample for naming out files
SAMPLE=$(basename "$FWD" _1P.fastq.gz)

# grab reverse reads
REV="${FWD/_1P.fastq.gz/_2P.fastq.gz}"

# script check-in
echo "Queueing sample: $SAMPLE"

# using the -M flag as best practice even though exome capture does not use the markDuplicates gatk workflow
bwa-mem2 mem -M -t "$SLURM_CPUS_PER_TASK" \
   "$REF" \
   "$FWD" "$REV" \
   | samtools sort -@ "$SLURM_CPUS_PER_TASK" -o "$OUT/${SAMPLE}.map.bam"

# metrics
samtools flagstat "$OUT/${SAMPLE}.map.bam" > "$METRICS/${SAMPLE}.flagstat.txt"
